We are very fortunate to have a powerful computing cluster to aid in research and development. Currently this cluster is composed by 4 identical rack-mounted (4u) computing nodes with GPGPU capability and an additional Supermicro head node that serves as the frontend node. The latter is used for issuing jobs or tasks, to be processed in the cluster, and for management, coordination and distribution of said jobs or tasks.

=== Software ===

Rocks Cluster Distribution 6.2 (CentOS 6.7)

== Network ==

To access the cluster you need to log on to the SSH server on 193.136.122.79.

All the nodes are interconnected using a Gigabit switch.

== Master node ==

=== Network ===

Host: 193.136.122.79

Internal: zarco.novasearch.org (10.1.1.1)

=== Hardware ===

{| class="wikitable"
| MB
| Intel DX58SO
|-
| CPU
| Intel Core i7-920 Processor (4 cores, 8 threads, 8M Cache, 2.66 GHz, up to 2.93 GHz)
|-
| RAM
| 12 GB DDR3 (1066Mhz)
|}

== Computing nodes ==

=== Network ===

compute-0-{0,1,2,3} (10.1.1.*)

=== Hardware ===

{| class="wikitable"
| MB
| ASUS P9X79 PRO
|-
| CPU
| Intel Core i7-3930K Processor (6 cores, 12 threads, 12M Cache, 3.2 GHz, up to 3.80 GHz)
|-
| RAM
| 64 GB DDR3 (1333Mhz)
|-
| GPU
| 2 x AMD Radeon HD 7950 3 GB
|}

== Security ==

The cluster uses Rocks and its Single Sign-On solution.

Users homes are also mounted on all the computing nodes with NFS allowing you to have access to your files on any node. Do however take in mind that if you're doing any intensive IO work it is always better to use a local folder on the computing node. Usually the norm is to use the root directory /tmp however all the files in this directory are removed upon reboot, so consider creating a new folder with your username inside the root directory /state/partition1 and use that instead if you want your data to persist.